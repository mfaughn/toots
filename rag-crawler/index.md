# Tutorial: rag-crawler

**RAG Crawler** is a tool that *crawls websites* and *extracts relevant content* to generate knowledge files for RAG (Retrieval-Augmented Generation). 
It allows users to **customize the crawling process** using various options and presets, making it adaptable to different websites and use cases.
The crawler can handle different types of content, including HTML pages and Markdown files on GitHub repositories.


**Source Repository:** [https://github.com/sigoden/rag-crawler](https://github.com/sigoden/rag-crawler)

```mermaid
flowchart TD
    A0["Crawl Options"]
    A1["Preset"]
    A2["Web Crawler"]
    A3["Page Processing"]
    A4["GitHub Tree Crawler"]
    A5["Command-Line Interface (CLI)"]
    A6["Output Handling"]
    A7["Logging and Error Handling"]
    A5 -- "Parses" --> A0
    A5 -- "Uses" --> A1
    A5 -- "Handles output" --> A6
    A2 -- "Uses config" --> A0
    A2 -- "Processes pages" --> A3
    A4 -- "Crawls GitHub tree" --> A2
    A1 -- "Provides defaults" --> A0
    A6 -- "Logs output" --> A7
    A2 -- "Logs progress" --> A7
    A3 -- "Logs errors" --> A7
```

## Chapters

1. [Command-Line Interface (CLI)](01_command_line_interface__cli_.md)
2. [Preset](02_preset.md)
3. [Crawl Options](03_crawl_options.md)
4. [Web Crawler](04_web_crawler.md)
5. [Page Processing](05_page_processing.md)
6. [Output Handling](06_output_handling.md)
7. [GitHub Tree Crawler](07_github_tree_crawler.md)
8. [Logging and Error Handling](08_logging_and_error_handling.md)


---

Generated by [AI Codebase Knowledge Builder](https://github.com/The-Pocket/Tutorial-Codebase-Knowledge)